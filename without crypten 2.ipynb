{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define the col names\n",
    "colnames=[\"sepal_length_in_cm\", \"sepal_width_in_cm\",\"petal_length_in_cm\",\"petal_width_in_cm\", \"class\"]\n",
    "\n",
    "#Read the dataset\n",
    "dataset = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", header = None, names= colnames )\n",
    "\n",
    "#Data\n",
    "dataset.head()\n",
    "\n",
    "#Encoding the categorical column\n",
    "dataset = dataset.replace({\"class\":  {\"Iris-setosa\":1,\"Iris-versicolor\":2, \"Iris-virginica\":3}})\n",
    "#Visualize the new dataset\n",
    "dataset.head()\n",
    "\n",
    "\n",
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "#make splits\n",
    "split1 = X_train.drop(columns=['sepal_length_in_cm','sepal_width_in_cm'])\n",
    "split2 = X_train.drop(columns=['petal_length_in_cm','petal_width_in_cm'])\n",
    "\n",
    "split1_test = X_test.drop(columns=['sepal_length_in_cm','sepal_width_in_cm'])\n",
    "split2_test = X_test.drop(columns=['petal_length_in_cm','petal_width_in_cm'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0  9]]\n",
      "Accuracy: 97.27 %\n",
      "Standard Deviation: 4.17 %\n"
     ]
    }
   ],
   "source": [
    "#Create the SVM model\n",
    "from sklearn.svm import SVC\n",
    "classifier1 = SVC(kernel = 'linear', random_state = 0)\n",
    "#Fit the model for the data\n",
    "\n",
    "classifier1.fit(split1, y_train)\n",
    "\n",
    "#Make the prediction\n",
    "y_pred = classifier1.predict(split1_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier1, X = split1, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 11  5]\n",
      " [ 0  4  5]]\n",
      "Accuracy: 81.29 %\n",
      "Standard Deviation: 13.68 %\n"
     ]
    }
   ],
   "source": [
    "#Create the SVM model\n",
    "from sklearn.svm import SVC\n",
    "classifier2 = SVC(kernel = 'linear', random_state = 0)\n",
    "#Fit the model for the data\n",
    "\n",
    "classifier2.fit(split2, y_train)\n",
    "\n",
    "#Make the prediction\n",
    "y_pred = classifier2.predict(split2_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier2, X = split2, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[classifier1,classifier2]\n",
    "splits=[split1_test,split2_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COINMPRO FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SyMPC imports required for encrypted inference\n",
    "import sympc\n",
    "from sympc.session import Session\n",
    "from sympc.session import SessionManager\n",
    "from sympc.tensor import MPCTensor\n",
    "from sympc.protocol import Falcon,FSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clients(n_parties):\n",
    "    parties=[]\n",
    "    for index in range(n_parties): \n",
    "        parties.append(sy.VirtualMachine(name = \"worker\"+str(index)).get_root_client())\n",
    "    return parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_send(data,session):\n",
    "    \"\"\"Splits data into number of chunks equal to number of parties and distributes it to respective \n",
    "       parties.\n",
    "    \"\"\"\n",
    "    data_pointers = []\n",
    "    \n",
    "    split_size = int(len(data)/len(session.parties))+1\n",
    "    for index in range(0,len(session.parties)):\n",
    "        ptr=data[index*split_size:index*split_size+split_size].share(session=session)\n",
    "        data_pointers.append(ptr)\n",
    "        \n",
    "    return data_pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(n_clients,Models,splits,protocol=None):\n",
    "    # Get VM clients \n",
    "    parties=get_clients(n_clients)\n",
    "\n",
    "  # Setup the session for the computation\n",
    "    if(protocol):\n",
    "        session = Session(parties = parties,protocol = protocol)\n",
    "    else:\n",
    "        session = Session(parties = parties)\n",
    "        \n",
    "    SessionManager.setup_mpc(session)\n",
    "    pointers=[]\n",
    "    mpc_model=[]\n",
    "\n",
    "    \n",
    "    for i in range(len(Models)):\n",
    "        #Split data and send data to clients\n",
    "        pointers.append(split_send(splits[i],session))\n",
    "\n",
    "        #Encrypt model \n",
    "        mpc_model.append(m[i].share(session))\n",
    "        \n",
    "        \n",
    "        \n",
    "   #INFERENCE FROM HERE\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(len(Models)): \n",
    "        results = []\n",
    "        for j in range(len(pointers[0])):\n",
    "            encrypted_results = mpc_model[i](pointers[i][j])  #may b with .predict\n",
    "            plaintext_results = encrypted_results.reconstruct()\n",
    "            results.append(plaintext_results)\n",
    "        predictions = torch.cat(results).reshape([-1])\n",
    "        \n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Time for inference: {end_time-start_time}s\")\n",
    "    \n",
    "    \n",
    "\n",
    "    #Calculate Loss\n",
    "    for i in range(len(Models)):\n",
    "        accuracies = cross_val_score(estimator = Models[i], X = splits[i], y = y_train, cv = 10)\n",
    "        print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "        print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
