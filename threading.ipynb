{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YJt95AY3LBt7"
   },
   "outputs": [],
   "source": [
    "#External libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1w2XFk41LJqN"
   },
   "outputs": [],
   "source": [
    "#Import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dp\n",
      "  Downloading python_dp-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 19.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: python-dp\n",
      "Successfully installed python-dp-1.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install python-dp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydp as dp  # by convention our package is to be imported as dp (for Differential Privacy!)\n",
    "from pydp.algorithms.laplacian import BoundedMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WIjhqLpuLJxQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8140a2c970>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set a manual seed to maintain consistency\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xb49SPpVLJ2j"
   },
   "source": [
    "<h2>Data Loading and Processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9rIrXsNeLJ63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://deb.debian.org/debian buster InRelease\n",
      "Get:2 http://deb.debian.org/debian buster-updates InRelease [51.9 kB]\n",
      "Get:3 http://security.debian.org/debian-security buster/updates InRelease [65.4 kB]\n",
      "Get:4 http://security.debian.org/debian-security buster/updates/main amd64 Packages [316 kB]\n",
      "Fetched 433 kB in 1s (560 kB/s)    \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  wget\n",
      "0 upgraded, 1 newly installed, 0 to remove and 1 not upgraded.\n",
      "Need to get 902 kB of archives.\n",
      "After this operation, 3335 kB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian buster/main amd64 wget amd64 1.20.1-1.1 [902 kB]\n",
      "Fetched 902 kB in 0s (42.9 MB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package wget.\n",
      "(Reading database ... 20003 files and directories currently installed.)\n",
      "Preparing to unpack .../wget_1.20.1-1.1_amd64.deb ...\n",
      "Unpacking wget (1.20.1-1.1) ...\n",
      "Setting up wget (1.20.1-1.1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BZCZFdjPLJ-v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-16 17:44:18--  https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49082 (48K) [application/x-httpd-php]\n",
      "Saving to: ‘housing.data’\n",
      "\n",
      "housing.data        100%[===================>]  47.93K   297KB/s    in 0.2s    \n",
      "\n",
      "2022-02-16 17:44:19 (297 KB/s) - ‘housing.data’ saved [49082/49082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Download Boston housing dataset\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BZa2H2ptLKC2"
   },
   "outputs": [],
   "source": [
    "#Import dataset and add headers\n",
    "dataset=pd.read_csv(\"housing.data\",delim_whitespace=True,\n",
    "                    names=[\"crim\",\"zn\",\"indus\",\n",
    "                           \"chas\",\"nox\",\"rm\",\n",
    "                           \"age\",\"dis\",\"rad\",\n",
    "                           \"tax\",\"ptratio\",\"black\",\n",
    "                           \"lstat\",\"medv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JCLSxU7uLKGn"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   ptratio   black  lstat  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize and look at columns and rows of dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "X2qDiB1RLKKJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   ptratio   black  lstat  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize and look at columns and rows of dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "#Split data into features and target variables\n",
    "features = dataset.drop(\"medv\",axis=1)\n",
    "targets = dataset[\"medv\"]\n",
    "print (min(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pZsLH3stLKNm"
   },
   "outputs": [],
   "source": [
    "#Normalize features\n",
    "features = features.apply(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "r4jBJ4P2LKQ_"
   },
   "outputs": [],
   "source": [
    "#Convert features and targets into torch tensors\n",
    "features = torch.tensor(features.values.astype(np.float32)) \n",
    "targets = torch.tensor(targets.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SLzdxpT7LKUG"
   },
   "outputs": [],
   "source": [
    "# Arguments for training\n",
    "batch_size = 16\n",
    "epochs = 300\n",
    "train_test_split = 0.8\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vvjL5pfnLKW-"
   },
   "outputs": [],
   "source": [
    "#Split dataset into train and test\n",
    "train_indices=int(len(features)*train_test_split)\n",
    "\n",
    "train_x = features[:train_indices]\n",
    "train_y = targets[:train_indices]\n",
    "\n",
    "test_x = features[train_indices+1:]\n",
    "test_y = targets[train_indices+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tfuL4IpHLKZ2"
   },
   "outputs": [],
   "source": [
    "#Divide dataset into batches\n",
    "def get_batches(X, y):\n",
    "    batches = []\n",
    "    for index in range(0,len(train_x)+1,batch_size):\n",
    "        batches.append((X[index:index+batch_size],y[index:index+batch_size]))\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoyS4zF2LKc3"
   },
   "source": [
    "<h1>Plaintext Training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bsj8zessLKfe"
   },
   "outputs": [],
   "source": [
    "#Import syft\n",
    "import syft as sy\n",
    "sy.logger.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1YbNIrxxLKiY"
   },
   "outputs": [],
   "source": [
    "#Define Linear regression model\n",
    "class LinearSyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(LinearSyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.fc1 = self.torch_ref.nn.Linear(13,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "hX0sEcNtLKlc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xtest=[]\\nxtest.append(np.array_split(test_x, nom))\\n\\nytest=[]\\nytest.append(np.array_split(test_y, nom))'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"xtest=[]\n",
    "xtest.append(np.array_split(test_x, nom))\n",
    "\n",
    "ytest=[]\n",
    "ytest.append(np.array_split(test_y, nom))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OCkN7O2UMDwT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n",
      "404\n"
     ]
    }
   ],
   "source": [
    "print(len(train_x))\n",
    "print(len(train_x[:404]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OSYE_brBMDzy"
   },
   "outputs": [],
   "source": [
    "def Train(nom,m):\n",
    "    #Training Loop\n",
    "    train_batches=get_batches(train_x,train_y)\n",
    "\n",
    "\n",
    "    for i in range(nom):\n",
    "\n",
    "        model1 = LinearSyNet(torch)\n",
    "        criterion = torch.nn.MSELoss(reduction='mean') \n",
    "        optimizer = torch.optim.SGD(model1.parameters(), lr=lr)\n",
    "        print(\"model: \", i)\n",
    "        for epoch in range(epochs):\n",
    "          running_loss = 0.0\n",
    "          for index in range(0,len(train_batches)):\n",
    "            # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # get output from the model, given the inputs\n",
    "            outputs = model1(train_batches[index][0]).reshape([-1])\n",
    "\n",
    "            # get loss for the predicted output\n",
    "            loss = criterion(outputs,train_batches[index][1])\n",
    "            running_loss += loss\n",
    "            # get gradients w.r.t to parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "          test_accuracy = criterion(model1(test_x).reshape([-1]),test_y)\n",
    "          if((epoch%50)==0):\n",
    "             b =0\n",
    "             print(f\"Epoch {epoch}/{epochs}  Running Loss : {running_loss.item()/batch_size} and test loss: {test_accuracy.item()}\")\n",
    "\n",
    "        m.append(model1)\n",
    "        return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr_g-a33MD3j"
   },
   "source": [
    "<h1>Encrypted Inference</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jhAiBfoKMD7e"
   },
   "outputs": [],
   "source": [
    "#SyMPC imports required for encrypted inference\n",
    "import sympc\n",
    "from sympc.session import Session\n",
    "from sympc.session import SessionManager\n",
    "from sympc.tensor import MPCTensor\n",
    "from sympc.protocol import Falcon,FSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vHHj_2bHMD_J"
   },
   "outputs": [],
   "source": [
    "def get_clients(n_parties):\n",
    "  #Generate required number of syft clients and return them.\n",
    "\n",
    "  parties=[]\n",
    "  for index in range(n_parties): \n",
    "      parties.append(sy.VirtualMachine(name = \"worker\"+str(index)).get_root_client())\n",
    "\n",
    "  return parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "PDiab9GvMEDJ"
   },
   "outputs": [],
   "source": [
    "def split_send(data,session):\n",
    "    \"\"\"Splits data into number of chunks equal to number of parties and distributes it to respective \n",
    "       parties.\n",
    "    \"\"\"\n",
    "    data_pointers = []\n",
    "    \n",
    "    split_size = int(len(data)/len(session.parties))+1\n",
    "    for index in range(0,len(session.parties)):\n",
    "        ptr=data[index*split_size:index*split_size+split_size].share(session=session)\n",
    "        data_pointers.append(ptr)\n",
    "        \n",
    "    return data_pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def private_mean(result,lower,upper,privacy_budget: float) -> float:\n",
    "    x = BoundedMean(privacy_budget,0,lower,upper, dtype=\"float\")\n",
    "    return x.quick_result(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(a):\n",
    "    b=[]\n",
    "    for i in range(len(a[0])):\n",
    "        b.append([])\n",
    "        for j in range(3):\n",
    "            b[i].append(a[j][i])\n",
    "    return(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def private_mean(result,lower,upper,privacy_budget: float) -> float:\n",
    "    x = BoundedMean(privacy_budget,0,lower,upper, dtype=\"float\")\n",
    "    return x.quick_result(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ._bounded_algorithms import Median\n",
    "from pydp.algorithms.laplacian import Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def private_median(result,lower,upper,privacy_budget: float) -> float:\n",
    "    x = Median(privacy_budget,0,lower,upper, dtype=\"float\")\n",
    "    return x.quick_result(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf(i,mpc_model,pointers,results,all_predictions):\n",
    "        \n",
    "    for j in range(len(pointers[0])):\n",
    "        encrypted_results = mpc_model[i](pointers[i][j])\n",
    "        plaintext_results = encrypted_results.reconstruct()\n",
    "        results.append(plaintext_results)\n",
    "    prediction = torch.cat(results).reshape([-1])\n",
    "    all_predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "na33TcYEMEGx"
   },
   "outputs": [],
   "source": [
    "def inference(n_clients,nom,privacy_budget,protocol=None):\n",
    "\n",
    "  m=[]\n",
    "  #criterion=Train(nom,m)\n",
    "  train_batches=get_batches(train_x,train_y)\n",
    "\n",
    "\n",
    "  for i in range(nom):\n",
    "\n",
    "    model1 = LinearSyNet(torch)\n",
    "    criterion = torch.nn.MSELoss(reduction='mean') \n",
    "    optimizer = torch.optim.SGD(model1.parameters(), lr=lr)\n",
    "    #print(\"model: \", i)\n",
    "    for epoch in range(epochs):\n",
    "      running_loss = 0.0\n",
    "      for index in range(0,len(train_batches)):\n",
    "        # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output from the model, given the inputs\n",
    "        outputs = model1(train_batches[index][0]).reshape([-1])\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        loss = criterion(outputs,train_batches[index][1])\n",
    "        running_loss += loss\n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "      test_accuracy = criterion(model1(test_x).reshape([-1]),test_y)\n",
    "      if((epoch%50)==0):\n",
    "         b =0\n",
    "         #print(f\"Epoch {epoch}/{epochs}  Running Loss : {running_loss.item()/batch_size} and test loss: {test_accuracy.item()}\")\n",
    "\n",
    "    m.append(model1)\n",
    "    \n",
    "  #print(\"models trained\")\n",
    "  # Get VM clients \n",
    "  parties=get_clients(n_clients)\n",
    "\n",
    "  # Setup the session for the computation\n",
    "  if(protocol):\n",
    "     session = Session(parties = parties,protocol = protocol)\n",
    "  else:\n",
    "     session = Session(parties = parties)\n",
    "        \n",
    "  SessionManager.setup_mpc(session)\n",
    "  pointers=[]\n",
    "  mpc_model=[]\n",
    "\n",
    "  \n",
    "  for i in range(nom):\n",
    "        #Split data and send data to clients\n",
    "        pointers.append(split_send(test_x,session))\n",
    "\n",
    "        #Encrypt model \n",
    "        mpc_model.append(m[i].share(session))\n",
    "  \n",
    "        #Encrypt test data\n",
    "        #test_data=MPCTensor(secret=test_x, session = session)\n",
    "  all_predictions=[]\n",
    "  ap=[]\n",
    "    \n",
    "    \n",
    "  start_time = time.time()\n",
    "  for i in range(nom):\n",
    "        results = []\n",
    "        inf(i,mpc_model,pointers,results,all_predictions)\n",
    "        \"\"\"t1 = threading.Thread(target=inf, args=(i,mpc_model,pointers,results,all_predictions,))\n",
    "        t1.start()\n",
    "        t1.join() \"\"\" \n",
    "  \n",
    "\n",
    "\n",
    "  transMatt=transpose(all_predictions)\n",
    "  mean=[]\n",
    "\n",
    "  for i in range(len(transMatt)):\n",
    "        for j in range(len(transMatt[0])):\n",
    "            transMatt[i][j]=transMatt[i][j].item()\n",
    "   \n",
    "  for i in transMatt:\n",
    "        x1 = private_median(i,min(i)-5,max(i)+5,privacy_budget)\n",
    "        mean.append(x1)\n",
    "  \n",
    "  end_time=time.time()\n",
    "  print(\"Inference time: \",str(end_time-start_time),\"seconds\")\n",
    "  print(\"MSE Loss mean-private: \",criterion(torch.Tensor(mean),test_y).item()) \n",
    "  \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WaDVTEjCMEKq",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secure nodes:  3\n",
      "models:  3\n",
      "Inference time:  1.6923036575317383 seconds\n",
      "MSE Loss mean-private:  29.227087020874023\n",
      "models:  4\n"
     ]
    }
   ],
   "source": [
    "#secure nodes, nom\n",
    "for i in range(3,11):\n",
    "    print(\"secure nodes: \",i)\n",
    "    for j in range(3,21):\n",
    "        print(\"models: \",j)\n",
    "        predictions=inference(i,j,0.8)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "testing-17thJan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
