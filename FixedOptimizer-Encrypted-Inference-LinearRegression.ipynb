{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4945612e",
   "metadata": {},
   "source": [
    "<h1> Encrypted Inference-Linear Regression</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdce7bf",
   "metadata": {},
   "source": [
    "Author:\n",
    "<ul>\n",
    "    <li>Hrishikesh Kamath - <a href=\"https://twitter.com/kamathhrishi\">Twitter</a> - <a href=\"https://github.com/kamathhrishi\">Github</a>\n",
    "</ul>\n",
    "Encrypted Inference is the process of performing inference with machine learning models such that model owner cannot observe the true input data nor can the data owner see the true model weights. The weights and data are encrypted by splitting them into shares and performiming computations according to a protocol. The general class of methods know as <b>Secure Multi Party Computation (SMPC)</b>. \n",
    "\n",
    "Below figure depicts MPC for ML models for 2 parties. \n",
    "\n",
    "<img height=\"600px\" width=\"600px\" src=\"Images/smpc_illustration.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943011cc",
   "metadata": {},
   "source": [
    "In this example we use Virtual Machine to demonstrate performing inference using SMPC. That is the workers are present on the same PC. If you want to understand how to perform remotely check out duet tutorials. \n",
    "In this example, we train a Linear regression model in plaintext on Boston Housing Dataset. Then we use the model for performing encrypted inference on test data. This tutorial uses protocol Falcon for 3 parties and SPDZ for 3 and 5 parties. \n",
    "\n",
    "In SyMPC the computation between parties occurs using a orchestrator which describes how computations should take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df3753ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running loss is nan\n",
    "#batch size\n",
    "#Define Linear regression model (figure out)\n",
    "#criterion = torch.nn.MSELoss(reduction='mean') \n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cfe9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#External libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b25677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67713542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa7a6ac6a10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set a manual seed to maintain consistency\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6b5a2a",
   "metadata": {},
   "source": [
    "<h2>Data Loading and Processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d5bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://deb.debian.org/debian buster InRelease\n",
      "Hit:2 http://deb.debian.org/debian buster-updates InRelease\n",
      "Hit:3 http://security.debian.org/debian-security buster/updates InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "wget is already the newest version (1.20.1-1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c09bbb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-15 13:21:44--  https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49082 (48K) [application/x-httpd-php]\n",
      "Saving to: ‘housing.data.6’\n",
      "\n",
      "housing.data.6      100%[===================>]  47.93K   314KB/s    in 0.2s    \n",
      "\n",
      "2022-01-15 13:21:45 (314 KB/s) - ‘housing.data.6’ saved [49082/49082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Download Boston housing dataset\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a38de5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset and add headers\n",
    "dataset=pd.read_csv(\"housing.data\",delim_whitespace=True,\n",
    "                    names=[\"crim\",\"zn\",\"indus\",\n",
    "                           \"chas\",\"nox\",\"rm\",\n",
    "                           \"age\",\"dis\",\"rad\",\n",
    "                           \"tax\",\"ptratio\",\"black\",\n",
    "                           \"lstat\",\"medv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "860112db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   ptratio   black  lstat  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize and look at columns and rows of dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03e1045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into features and target variables\n",
    "features = dataset.drop(\"medv\",axis=1)\n",
    "targets = dataset[\"medv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f0ed65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize features\n",
    "features = features.apply(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7c38c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419367</td>\n",
       "      <td>0.284548</td>\n",
       "      <td>-1.286636</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.144075</td>\n",
       "      <td>0.413263</td>\n",
       "      <td>-0.119895</td>\n",
       "      <td>0.140075</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.665949</td>\n",
       "      <td>-1.457558</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-1.074499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.416927</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-0.592794</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.739530</td>\n",
       "      <td>0.194082</td>\n",
       "      <td>0.366803</td>\n",
       "      <td>0.556609</td>\n",
       "      <td>-0.867024</td>\n",
       "      <td>-0.986353</td>\n",
       "      <td>-0.302794</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-0.491953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.416929</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-0.592794</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.739530</td>\n",
       "      <td>1.281446</td>\n",
       "      <td>-0.265549</td>\n",
       "      <td>0.556609</td>\n",
       "      <td>-0.867024</td>\n",
       "      <td>-0.986353</td>\n",
       "      <td>-0.302794</td>\n",
       "      <td>0.396035</td>\n",
       "      <td>-1.207532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416338</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-1.305586</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.834458</td>\n",
       "      <td>1.015298</td>\n",
       "      <td>-0.809088</td>\n",
       "      <td>1.076671</td>\n",
       "      <td>-0.752178</td>\n",
       "      <td>-1.105022</td>\n",
       "      <td>0.112920</td>\n",
       "      <td>0.415751</td>\n",
       "      <td>-1.360171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412074</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>-1.305586</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.834458</td>\n",
       "      <td>1.227362</td>\n",
       "      <td>-0.510674</td>\n",
       "      <td>1.076671</td>\n",
       "      <td>-0.752178</td>\n",
       "      <td>-1.105022</td>\n",
       "      <td>0.112920</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-1.025487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.412820</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>0.115624</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>0.157968</td>\n",
       "      <td>0.438881</td>\n",
       "      <td>0.018654</td>\n",
       "      <td>-0.625178</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.802418</td>\n",
       "      <td>1.175303</td>\n",
       "      <td>0.386834</td>\n",
       "      <td>-0.417734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-0.414839</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>0.115624</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>0.157968</td>\n",
       "      <td>-0.234316</td>\n",
       "      <td>0.288648</td>\n",
       "      <td>-0.715931</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.802418</td>\n",
       "      <td>1.175303</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-0.500355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>-0.413038</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>0.115624</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>0.157968</td>\n",
       "      <td>0.983986</td>\n",
       "      <td>0.796661</td>\n",
       "      <td>-0.772919</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.802418</td>\n",
       "      <td>1.175303</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-0.982076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>-0.407361</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>0.115624</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>0.157968</td>\n",
       "      <td>0.724955</td>\n",
       "      <td>0.736268</td>\n",
       "      <td>-0.667776</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.802418</td>\n",
       "      <td>1.175303</td>\n",
       "      <td>0.402826</td>\n",
       "      <td>-0.864446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>-0.414590</td>\n",
       "      <td>-0.487240</td>\n",
       "      <td>0.115624</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>0.157968</td>\n",
       "      <td>-0.362408</td>\n",
       "      <td>0.434302</td>\n",
       "      <td>-0.612640</td>\n",
       "      <td>-0.981871</td>\n",
       "      <td>-0.802418</td>\n",
       "      <td>1.175303</td>\n",
       "      <td>0.440616</td>\n",
       "      <td>-0.668397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         crim        zn     indus      chas       nox        rm       age  \\\n",
       "0   -0.419367  0.284548 -1.286636 -0.272329 -0.144075  0.413263 -0.119895   \n",
       "1   -0.416927 -0.487240 -0.592794 -0.272329 -0.739530  0.194082  0.366803   \n",
       "2   -0.416929 -0.487240 -0.592794 -0.272329 -0.739530  1.281446 -0.265549   \n",
       "3   -0.416338 -0.487240 -1.305586 -0.272329 -0.834458  1.015298 -0.809088   \n",
       "4   -0.412074 -0.487240 -1.305586 -0.272329 -0.834458  1.227362 -0.510674   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "501 -0.412820 -0.487240  0.115624 -0.272329  0.157968  0.438881  0.018654   \n",
       "502 -0.414839 -0.487240  0.115624 -0.272329  0.157968 -0.234316  0.288648   \n",
       "503 -0.413038 -0.487240  0.115624 -0.272329  0.157968  0.983986  0.796661   \n",
       "504 -0.407361 -0.487240  0.115624 -0.272329  0.157968  0.724955  0.736268   \n",
       "505 -0.414590 -0.487240  0.115624 -0.272329  0.157968 -0.362408  0.434302   \n",
       "\n",
       "          dis       rad       tax   ptratio     black     lstat  \n",
       "0    0.140075 -0.981871 -0.665949 -1.457558  0.440616 -1.074499  \n",
       "1    0.556609 -0.867024 -0.986353 -0.302794  0.440616 -0.491953  \n",
       "2    0.556609 -0.867024 -0.986353 -0.302794  0.396035 -1.207532  \n",
       "3    1.076671 -0.752178 -1.105022  0.112920  0.415751 -1.360171  \n",
       "4    1.076671 -0.752178 -1.105022  0.112920  0.440616 -1.025487  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "501 -0.625178 -0.981871 -0.802418  1.175303  0.386834 -0.417734  \n",
       "502 -0.715931 -0.981871 -0.802418  1.175303  0.440616 -0.500355  \n",
       "503 -0.772919 -0.981871 -0.802418  1.175303  0.440616 -0.982076  \n",
       "504 -0.667776 -0.981871 -0.802418  1.175303  0.402826 -0.864446  \n",
       "505 -0.612640 -0.981871 -0.802418  1.175303  0.440616 -0.668397  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e7111a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      24.0\n",
       "1      21.6\n",
       "2      34.7\n",
       "3      33.4\n",
       "4      36.2\n",
       "       ... \n",
       "501    22.4\n",
       "502    20.6\n",
       "503    23.9\n",
       "504    22.0\n",
       "505    11.9\n",
       "Name: medv, Length: 506, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "085f5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert features and targets into torch tensors\n",
    "features = torch.tensor(features.values.astype(np.float32)) \n",
    "targets = torch.tensor(targets.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d775369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for training\n",
    "batch_size = 16\n",
    "epochs = 300\n",
    "train_test_split = 0.8\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83aaf309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into train and test\n",
    "train_indices=int(len(features)*train_test_split)\n",
    "\n",
    "train_x = features[:train_indices]\n",
    "train_y = targets[:train_indices]\n",
    "\n",
    "test_x = features[train_indices+1:]\n",
    "test_y = targets[train_indices+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d12eb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of models to b created: 5\n"
     ]
    }
   ],
   "source": [
    "nom = int(input(\"Enter number of models to b created: \"))\n",
    "m=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "034b0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=[]\n",
    "xtrain.append(np.array_split(train_x, nom))\n",
    "\n",
    "ytrain=[]\n",
    "ytrain.append(np.array_split(train_y, nom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "394b765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide dataset into batches\n",
    "def get_batches(X, y):\n",
    "    batches = []\n",
    "    for index in range(0,len(train_x)+1,batch_size):\n",
    "        batches.append((X[index:index+batch_size],y[index:index+batch_size]))\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e98f4a3",
   "metadata": {},
   "source": [
    "<h1>Plaintext Training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fba7d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import syft\n",
    "import syft as sy\n",
    "sy.logger.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f9c72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Linear regression model\n",
    "class LinearSyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(LinearSyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.fc1 = self.torch_ref.nn.Linear(13,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8636bc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Define model, loss function and optimizer\\nfor i in range(nom):\\n    model1 = LinearSyNet(torch)\\n    m.append(model1)\\ncriterion = torch.nn.MSELoss(reduction='mean') \\noptimizer = torch.optim.SGD(model.parameters(), lr=lr)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Define model, loss function and optimizer\n",
    "for i in range(nom):\n",
    "    model1 = LinearSyNet(torch)\n",
    "    m.append(model1)\n",
    "criterion = torch.nn.MSELoss(reduction='mean') \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f44dab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=[]\n",
    "xtest.append(np.array_split(test_x, nom))\n",
    "\n",
    "ytest=[]\n",
    "ytest.append(np.array_split(test_y, nom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5ba6086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n",
      "404\n"
     ]
    }
   ],
   "source": [
    "print(len(train_x))\n",
    "print(len(train_x[:404]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c1de79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  0\n",
      "Epoch 0/300  Running Loss : 978.0777587890625 and test loss: 367.94952392578125\n",
      "Epoch 50/300  Running Loss : 52.76874923706055 and test loss: 108.14092254638672\n",
      "Epoch 100/300  Running Loss : 43.0278434753418 and test loss: 47.97173309326172\n",
      "Epoch 150/300  Running Loss : 41.08037567138672 and test loss: 30.05457305908203\n",
      "Epoch 200/300  Running Loss : 40.12329864501953 and test loss: 23.080204010009766\n",
      "Epoch 250/300  Running Loss : 39.579410552978516 and test loss: 20.645092010498047\n",
      "model:  1\n",
      "Epoch 0/300  Running Loss : 1006.2069091796875 and test loss: 355.1054992675781\n",
      "Epoch 50/300  Running Loss : 53.09187698364258 and test loss: 110.3436050415039\n",
      "Epoch 100/300  Running Loss : 43.0759391784668 and test loss: 48.66814422607422\n",
      "Epoch 150/300  Running Loss : 41.09862518310547 and test loss: 30.31635856628418\n",
      "Epoch 200/300  Running Loss : 40.13597869873047 and test loss: 23.175142288208008\n",
      "Epoch 250/300  Running Loss : 39.59026336669922 and test loss: 20.673261642456055\n",
      "model:  2\n",
      "Epoch 0/300  Running Loss : 988.4722290039062 and test loss: 358.147705078125\n",
      "Epoch 50/300  Running Loss : 52.93144226074219 and test loss: 112.13249969482422\n",
      "Epoch 100/300  Running Loss : 43.13493728637695 and test loss: 49.406272888183594\n",
      "Epoch 150/300  Running Loss : 41.16222381591797 and test loss: 30.615041732788086\n",
      "Epoch 200/300  Running Loss : 40.18720245361328 and test loss: 23.276138305664062\n",
      "Epoch 250/300  Running Loss : 39.6295280456543 and test loss: 20.682157516479492\n",
      "model:  3\n",
      "Epoch 0/300  Running Loss : 1009.952392578125 and test loss: 329.2429504394531\n",
      "Epoch 50/300  Running Loss : 52.914222717285156 and test loss: 108.63787841796875\n",
      "Epoch 100/300  Running Loss : 43.10272979736328 and test loss: 48.368106842041016\n",
      "Epoch 150/300  Running Loss : 41.11921691894531 and test loss: 30.31989097595215\n",
      "Epoch 200/300  Running Loss : 40.1476936340332 and test loss: 23.24505615234375\n",
      "Epoch 250/300  Running Loss : 39.59605407714844 and test loss: 20.73955726623535\n",
      "model:  4\n",
      "Epoch 0/300  Running Loss : 965.5076293945312 and test loss: 332.89654541015625\n",
      "Epoch 50/300  Running Loss : 52.609500885009766 and test loss: 105.93644714355469\n",
      "Epoch 100/300  Running Loss : 42.9736328125 and test loss: 47.298370361328125\n",
      "Epoch 150/300  Running Loss : 41.02622604370117 and test loss: 29.851181030273438\n",
      "Epoch 200/300  Running Loss : 40.07943344116211 and test loss: 23.064739227294922\n",
      "Epoch 250/300  Running Loss : 39.54555130004883 and test loss: 20.703413009643555\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "train_batches=get_batches(train_x,train_y)\n",
    "\n",
    "\n",
    "for i in range(nom):\n",
    "\n",
    "    model1 = LinearSyNet(torch)\n",
    "    criterion = torch.nn.MSELoss(reduction='mean') \n",
    "    optimizer = torch.optim.SGD(model1.parameters(), lr=lr)\n",
    "    print(\"model: \", i)\n",
    "    for epoch in range(epochs):\n",
    "      running_loss = 0.0\n",
    "      for index in range(0,len(train_batches)):\n",
    "        # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output from the model, given the inputs\n",
    "        outputs = model1(train_batches[index][0]).reshape([-1])\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        loss = criterion(outputs,train_batches[index][1])\n",
    "        running_loss += loss\n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "      test_accuracy = criterion(model1(test_x).reshape([-1]),test_y)\n",
    "      if((epoch%50)==0):\n",
    "         b =0\n",
    "         print(f\"Epoch {epoch}/{epochs}  Running Loss : {running_loss.item()/batch_size} and test loss: {test_accuracy.item()}\")\n",
    "            \n",
    "    m.append(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4192669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Training Loop\\nfor i in range(nom):\\n    train_batches=get_batches(train_x,train_y)\\n    print(\"model: \", i)\\n    for epoch in range(epochs):\\n      running_loss = 0.0\\n      for index in range(0,len(train_batches)):\\n        # Clear gradient buffers because we don\\'t want any gradient from previous epoch to carry forward, dont want to cummulate gradients\\n        optimizer.zero_grad()\\n\\n        # get output from the model, given the inputs\\n        outputs = m[i](train_batches[index][0]).reshape([-1])\\n\\n        # get loss for the predicted output\\n        loss = criterion(outputs,train_batches[index][1])\\n        running_loss += loss\\n        # get gradients w.r.t to parameters\\n        loss.backward()\\n\\n        # update parameters\\n        optimizer.step()\\n\\n      test_accuracy = criterion(m[i](xtest[0][i]).reshape([-1]),ytest[0][i])#use xtest and ytest\\n      if((epoch%50)==0):\\n         print(f\"Epoch {epoch}/{epochs}  Running Loss : {running_loss.item()/batch_size} and test loss: {test_accuracy.item()}\")'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Training Loop\n",
    "for i in range(nom):\n",
    "    train_batches=get_batches(train_x,train_y)\n",
    "    print(\"model: \", i)\n",
    "    for epoch in range(epochs):\n",
    "      running_loss = 0.0\n",
    "      for index in range(0,len(train_batches)):\n",
    "        # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output from the model, given the inputs\n",
    "        outputs = m[i](train_batches[index][0]).reshape([-1])\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        loss = criterion(outputs,train_batches[index][1])\n",
    "        running_loss += loss\n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "      test_accuracy = criterion(m[i](xtest[0][i]).reshape([-1]),ytest[0][i])#use xtest and ytest\n",
    "      if((epoch%50)==0):\n",
    "         print(f\"Epoch {epoch}/{epochs}  Running Loss : {running_loss.item()/batch_size} and test loss: {test_accuracy.item()}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3a2e0c",
   "metadata": {},
   "source": [
    "<h1>Encrypted Inference</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4ba3c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SyMPC imports required for encrypted inference\n",
    "import sympc\n",
    "from sympc.session import Session\n",
    "from sympc.session import SessionManager\n",
    "from sympc.tensor import MPCTensor\n",
    "from sympc.protocol import Falcon,FSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "099f2b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clients(n_parties):\n",
    "  #Generate required number of syft clients and return them.\n",
    "\n",
    "  parties=[]\n",
    "  for index in range(n_parties): \n",
    "      parties.append(sy.VirtualMachine(name = \"worker\"+str(index)).get_root_client())\n",
    "\n",
    "  return parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cbab6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_send(data,session):\n",
    "    \"\"\"Splits data into number of chunks equal to number of parties and distributes it to respective \n",
    "       parties.\n",
    "    \"\"\"\n",
    "    data_pointers = []\n",
    "    \n",
    "    split_size = int(len(data)/len(session.parties))+1\n",
    "    for index in range(0,len(session.parties)):\n",
    "        ptr=data[index*split_size:index*split_size+split_size].share(session=session)\n",
    "        data_pointers.append(ptr)\n",
    "        \n",
    "    return data_pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49737ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "632d366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(n_clients,protocol=None):\n",
    "    \n",
    "    \n",
    "  # Get VM clients \n",
    "  parties=get_clients(n_clients)\n",
    "\n",
    "  # Setup the session for the computation\n",
    "  if(protocol):\n",
    "     session = Session(parties = parties,protocol = protocol)\n",
    "  else:\n",
    "     session = Session(parties = parties)\n",
    "        \n",
    "  SessionManager.setup_mpc(session)\n",
    "  pointers=[]\n",
    "  mpc_model=[]\n",
    "  for i in range(nom):\n",
    "        #Split data and send data to clients\n",
    "        pointers.append(split_send(xtest[0][i],session))\n",
    "\n",
    "        #Encrypt model \n",
    "        mpc_model.append(m[i].share(session))\n",
    "\n",
    "        #Encrypt test data\n",
    "        #test_data=MPCTensor(secret=test_x, session = session)\n",
    "  for i in range(nom):\n",
    "        #Perform inference and measure time taken\n",
    "        start_time = time.time()\n",
    "\n",
    "        results = []\n",
    "        #print(len(pointers[1]))\n",
    "        for j in range(len(pointers[0])):\n",
    "            encrypted_results = mpc_model[i](pointers[i][j])\n",
    "            plaintext_results = encrypted_results.reconstruct()\n",
    "            results.append(plaintext_results)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"Time for inference: {end_time-start_time}s\")\n",
    "\n",
    "        predictions = torch.cat(results).reshape([-1])\n",
    "\n",
    "        #Calculate Loss\n",
    "        print(\"MSE Loss: \",criterion(predictions,ytest[0][i]).item())\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b35ec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for inference: 0.153364896774292s\n",
      "MSE Loss:  53.92003631591797\n"
     ]
    }
   ],
   "source": [
    "predictions=inference(3,Falcon(\"semi-honest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec10fe5a",
   "metadata": {},
   "source": [
    "We can see that the prediction values and mean squared error values are almost the same as final model. Small differences are due to precision loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1bea240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0\n",
      "Encrypted Prediction Output 2.636962890625\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plaintext_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-78dd65e2029c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Index {index}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Encrypted Prediction Output {predictions[index].item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Plaintext Prediction Output {plaintext_predictions[index].item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected Prediction: {test_y[index]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plaintext_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "for index in range(0,10):\n",
    "    print(f\"Index {index}\")\n",
    "    print(f\"Encrypted Prediction Output {predictions[index].item()}\")\n",
    "    print(f\"Plaintext Prediction Output {plaintext_predictions[index].item()}\")\n",
    "    print(f\"Expected Prediction: {test_y[index]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3de12f",
   "metadata": {},
   "source": [
    "<h1> Conclusion </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017c5bb7",
   "metadata": {},
   "source": [
    "Falcon can also provide a malicious security guarantee for an honest majority at the cost of higher inference time. Malicious security ensures that all the parties compute according to the protocol and do not deviate from protocol or tamper with shares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0671bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=inference(3,Falcon(\"malicious\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e543e93",
   "metadata": {},
   "source": [
    "When we do not pass any protocol to session, SyMPC uses SPDZ and FSS protocol with semi-honest security type. \n",
    "\n",
    "SPDZ is used for multiplication and related operations (convolution,matmul,etc).\n",
    "Functional Secret Sharing (FSS) for other operations such as comparison, equality, maxpool, etc. \n",
    "\n",
    "FSS works only for 2 parties while SPDZ could extend to N parties. \n",
    "\n",
    "Linear regression uses only matmul which utilizes SPDZ protocol allowing us to run linear regression with several parties in this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038bbe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=inference(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=inference(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions=inference(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8325a69",
   "metadata": {},
   "source": [
    "<center><h3> Comparison </h3></center>\n",
    "\n",
    "| Protocol | Security Type| Parties | Inference Time (s) |\n",
    "| --- | --- | --- | --- |\n",
    "| Plaintext | |  | 0.000534|\n",
    "| Falcon | Semi-honest | 3 | 0.118 |\n",
    "| Falcon | Malicious | 3 | 0.6659 |\n",
    "| SPDZ| Semi-honest | 3 | 0.4993 |\n",
    "| SPDZ | Semi-honest | 5 | 1.3192|\n",
    "\n",
    "<b>Note:</b> The above table is only for comparison. The inference time varies for different PC specs and CPU load.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092cecc",
   "metadata": {},
   "source": [
    "Falcon provides faster inference for a 3 parties setting. While, SPDZ allows inference for N number of parties. Both allow inference with almost same accuracy as plaintext. \n",
    "\n",
    "Although Falcon is much more faster, it isn't scalable because it is applicable for only 3 parties. Further, it is less secure. Since it uses 2-out-of-3 sharing where each party recieves two shares allowing 2 parties to reconstruct a secret without other party knowing. Falcon also assumes that majority of parties are honest (2 in this case). \n",
    "\n",
    "While, SPDZ and FSS distributes a single share to every party requiring shares from all parties for reconstruction ensuring no parties could collude. Currently SyMPC provides support for SPDZ and FSS with semi-honest security guarantee. This allows parties to tamper with shares leading to incorrect results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef4aaf",
   "metadata": {},
   "source": [
    "<h3>What's next?</h3>\n",
    "\n",
    "SyMPC is still under development! We will add here more features as soon they are stable enough, stay tuned! 🕺\n",
    "\n",
    "If you enjoyed this tutorial, show your support by Starring SyMPC! 🙏"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
