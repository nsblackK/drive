{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3468eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypten\n",
    "import torch\n",
    "import crypten.mpc as mpc\n",
    "\n",
    "crypten.init()\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b84260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8906f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source argument values for Alice and Bob\n",
    "ALICE = 0\n",
    "BOB = 1\n",
    "CHARLIE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81c57ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mnist and normalize\n",
    "def _get_norm_mnist(dir=\"/tmp\", reduced=None, binary=False):\n",
    "    \"\"\"Downloads and normalizes mnist\"\"\"\n",
    "    mnist_train = datasets.MNIST(dir, download=True, train=True)\n",
    "    mnist_test = datasets.MNIST(dir, download=True, train=False)\n",
    "\n",
    "    # compute normalization factors\n",
    "    data_all = torch.cat([mnist_train.data, mnist_test.data]).float()\n",
    "    data_mean, data_std = data_all.mean(), data_all.std()\n",
    "    tensor_mean, tensor_std = data_mean.unsqueeze(0), data_std.unsqueeze(0)\n",
    "\n",
    "    # normalize\n",
    "    mnist_train_norm = transforms.functional.normalize(\n",
    "        mnist_train.data.float(), tensor_mean, tensor_std\n",
    "    )\n",
    "    mnist_test_norm = transforms.functional.normalize(\n",
    "        mnist_test.data.float(), tensor_mean, tensor_std\n",
    "    )\n",
    "    \n",
    "    # change all nonzero labels to 1 if binary classification required\n",
    "    if binary:\n",
    "        mnist_train.targets[mnist_train.targets != 0] = 1\n",
    "        mnist_test.targets[mnist_test.targets != 0] = 1\n",
    "\n",
    "    # create a reduced dataset if required\n",
    "    if reduced is not None:\n",
    "        mnist_norm = (mnist_train_norm[:reduced], mnist_test_norm[:reduced])\n",
    "        mnist_labels = (mnist_train.targets[:reduced], mnist_test.targets[:reduced])\n",
    "    else:\n",
    "        mnist_norm = (mnist_train_norm, mnist_test_norm)\n",
    "        mnist_labels = (mnist_train.targets, mnist_test.targets)\n",
    "    return mnist_norm, mnist_labels\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#split features and lables\n",
    "def split_features_v_labels(dir=\"/tmp\", party1=\"alice\", party2=\"bob\", reduced=None, binary=False):\n",
    "    \"\"\"Gives Party 1 features and Party 2 labels\"\"\"\n",
    "    mnist_norm, mnist_labels = _get_norm_mnist(dir, reduced, binary)\n",
    "    mnist_train_norm, mnist_test_norm = mnist_norm\n",
    "    mnist_train_labels, mnist_test_labels = mnist_labels\n",
    "    \n",
    "    #Alice has features(train and test)\n",
    "    torch.save(mnist_train_norm, os.path.join(dir, party1 + \"_train.pth\"))\n",
    "    torch.save(mnist_test_norm, os.path.join(dir, party1 + \"_test.pth\"))\n",
    "    \n",
    "    #save from party\n",
    "    crypten.save_from_party(mnist_train_norm, '/tmp/alice_train.pth', src=ALICE)\n",
    "    crypten.save_from_party(mnist_test_norm, '/tmp/alice_test.pth', src=ALICE)\n",
    "    \n",
    "    \n",
    "    #Bob has labels(train and test)\n",
    "    torch.save(mnist_train_labels, os.path.join(dir, party2 + \"_train_labels.pth\"))\n",
    "    torch.save(mnist_test_labels, os.path.join(dir, party2 + \"_test_labels.pth\"))\n",
    "\n",
    "    #save from party\n",
    "    crypten.save_from_party(mnist_train_labels, '/tmp/bob_train_labels.pth', src=BOB)\n",
    "    crypten.save_from_party(mnist_test_labels, '/tmp/bob_test_labels.pth', src=BOB)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def split_features(mnist_norm, split=0.5, dir=\"/tmp\", party1=\"alice\", party2=\"bob\", reduced=None, binary=False):\n",
    "    \"\"\"Splits features between Party 1 and Party 2\"\"\"\n",
    "    \n",
    "#     mnist_train_norm, mnist_test_norm = mnist_norm\n",
    "#     mnist_train_labels, mnist_test_labels = mnist_labels\n",
    "\n",
    "    num_features = mnist_norm.shape[1]\n",
    "    split_point = int(split * num_features)\n",
    "\n",
    "    party1_train = mnist_norm[:, :, :split_point]\n",
    "    party2_train = mnist_norm[:, :, split_point:]\n",
    "#     party1_test = mnist_test_norm[:, :, :split_point]\n",
    "#     party2_test = mnist_test_norm[:, :, split_point:]\n",
    "\n",
    "    torch.save(party1_train, os.path.join(dir, party1 + \"_train.pth\"))\n",
    "    torch.save(party2_train, os.path.join(dir, party2 + \"_train.pth\"))\n",
    "\n",
    "#     torch.save(party1_test, os.path.join(dir, party1 + \"_test.pth\"))\n",
    "#     torch.save(party2_test, os.path.join(dir, party2 + \"_test.pth\"))\n",
    "#     torch.save(mnist_train_labels, os.path.join(dir, \"train_labels.pth\"))\n",
    "#     torch.save(mnist_test_labels, os.path.join(dir, \"test_labels.pth\"))    \n",
    "    \n",
    "    crypten.save_from_party(party1_train, '/tmp/s1_alice_train_labels.pth', src=ALICE)\n",
    "\n",
    "    crypten.save_from_party(party2_train, '/tmp/s2_charlie_test_labels.pth', src=BOB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d513ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Define an example network\n",
    "class ExampleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExampleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=0)\n",
    "        self.fc1 = nn.Linear(16 * 12 * 12, 100)\n",
    "        self.fc2 = nn.Linear(100, 2) # For binary classification, final layer needs only 2 outputs\n",
    " \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 16 * 12 * 12)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "crypten.common.serial.register_safe_class(ExampleNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ce4c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label shape: label shape:   torch.Size([60000])\n",
      "torch.Size([60000])\n",
      "split1 shape: split1 shape:  torch.Size([60000, 28, 14]) torch.Size([60000, 28, 14])\n",
      "\n",
      "till here\n",
      "till here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-21:\n",
      "Process Process-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py38_default/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py38_default/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda/envs/py38_default/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nsblack/crypten/CrypTen/crypten/mpc/context.py\", line 30, in _launch\n",
      "    return_value = func(*func_args, **func_kwargs)\n",
      "  File \"/anaconda/envs/py38_default/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nsblack/crypten/CrypTen/crypten/mpc/context.py\", line 30, in _launch\n",
      "    return_value = func(*func_args, **func_kwargs)\n",
      "  File \"/tmp/ipykernel_22972/2240038617.py\", line 36, in loadData\n",
      "    w, b = train_linear_svm(mnist_train_norm, mnist_train_labels, epochs=40, lr=0.001)\n",
      "  File \"/tmp/ipykernel_22972/2240038617.py\", line 36, in loadData\n",
      "    w, b = train_linear_svm(mnist_train_norm, mnist_train_labels, epochs=40, lr=0.001)\n",
      "  File \"/home/nsblack/crypten/CrypTen/examples/mpc_linear_svm/mpc_linear_svm.py\", line 27, in train_linear_svm\n",
      "    label_predictions = w.matmul(features).add(b).sign()\n",
      "  File \"/home/nsblack/crypten/CrypTen/examples/mpc_linear_svm/mpc_linear_svm.py\", line 27, in train_linear_svm\n",
      "    label_predictions = w.matmul(features).add(b).sign()\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (1680000x28 and 60000x1)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (1680000x28 and 60000x1)\n",
      "ERROR:root:One of the parties failed. Check past logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "#Alice has features and bob has labels\n",
    "import crypten.mpc as mpc\n",
    "import crypten.communicator as comm\n",
    "from sklearn.svm import SVC\n",
    "from examples.mpc_linear_svm.mpc_linear_svm import train_linear_svm, evaluate_linear_svm\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def loadData(dir=\"/tmp\", party1=\"alice\", party2=\"bob\", reduced=None, binary=False):\n",
    "    \n",
    "    #getting mnist data\n",
    "    mnist_norm, mnist_labels = _get_norm_mnist(dir, reduced, binary)\n",
    "    \n",
    "    #features train test split\n",
    "    mnist_train_norm, mnist_test_norm = mnist_norm\n",
    "    \n",
    "    #labels train test split\n",
    "    mnist_train_labels, mnist_test_labels = mnist_labels\n",
    "    \n",
    "    #split features\n",
    "    split_features(mnist_train_norm)\n",
    "    \n",
    "    #loading split1 and split2\n",
    "    split1 = crypten.load_from_party('/tmp/s1_alice_train_labels.pth', src=ALICE)\n",
    "    split2 = crypten.load_from_party('/tmp/s2_charlie_test_labels.pth', src=BOB)\n",
    "\n",
    "    #encrypting train labels\n",
    "    torch.save(mnist_train_labels, os.path.join(dir, party2 + \"_train_labels.pth\"))\n",
    "    crypten.save_from_party(mnist_train_labels, '/tmp/bob_train_labels.pth', src=BOB)\n",
    "    label = crypten.load_from_party('/tmp/bob_train_labels.pth', src=BOB)\n",
    "    \n",
    "\n",
    "    print(\"label shape: \",label.shape) \n",
    "    print(\"split1 shape: \",split1.shape) \n",
    "    #train(split1, label_oh)\n",
    "    print(\"till here\")\n",
    "    w, b = train_linear_svm(split1, label, epochs=40, lr=0.001)\n",
    "    print(\"training done!\")\n",
    "    # Evaluate model\n",
    "    evaluate_linear_svm(mnist_test_norm, mnist_test_labels, w, b)\n",
    "               \n",
    "    #train(split2, label_oh)\n",
    "               \n",
    "\n",
    "loadData()\n",
    "print(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf03a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ca149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
